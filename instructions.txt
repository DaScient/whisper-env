Hereâ€™s exactly how to get Whisper working on your machine:

â¸»

ğŸš€ Whisper on MacBook (M2, M2 Max, M1, etc.)

ğŸ›  Step 1: Install Homebrew (if not installed)

/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"


â¸»

ğŸ›  Step 2: Install dependencies

brew install ffmpeg


â¸»

ğŸ›  Step 3: Create a Python environment (recommended)

python3 -m venv whisper-env
source whisper-env/bin/activate


â¸»

ğŸ›  Step 4: Install Whisper and PyTorch (with MPS support)

pip install --upgrade pip setuptools wheel

# Install PyTorch with MPS (Metal backend for Apple Silicon)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# Install Whisper
pip install openai-whisper


â¸»

ğŸ“ Whisper Transcription Script

Save this as transcribe_whisper.py in the same folder as your example.m4a:

import whisper

# Load Whisper model (tiny, base, small, medium, large)
model = whisper.load_model("base")

# Path to your audio file
audio_path = "example.m4a"
output_text_file = "example_transcription.txt"

# Transcribe
print(f"Transcribing {audio_path} ...")
result = model.transcribe(audio_path)

# Save transcript
with open(output_text_file, "w") as f:
    f.write(result["text"])

print("âœ… Transcription complete!")
print(f"Transcript saved to {output_text_file}")


â¸»

ğŸ›  Step 5: Run the transcription

python transcribe_whisper.py


â¸»

âœ… This will generate a file called example_transcription.txt with your output.

â¸»
